{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88011"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "    ]\n",
    ")\n",
    "\n",
    "dataset = ImageFolder(\"train/\", transform= transform)\n",
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e9ffa55a10>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 892\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14011 74000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "148"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = 500\n",
    "train_size = 74000\n",
    "\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "\n",
    "val_dataset, train_dataset = data.random_split(dataset, lengths=[val_size, train_size])\n",
    "\n",
    "train_loader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, drop_last=True, num_workers=1)\n",
    "val_loader = data.DataLoader(val_dataset, batch_size=100, pin_memory=True, num_workers=1)\n",
    "print(len(val_dataset), len(train_dataset))\n",
    "int(len(train_dataset)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifierNetwork(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    def train_step(self, input, labels):\n",
    "        input = input.to(device=device)#, non_blocking=True)\n",
    "        labels = labels.to(device=device)#, non_blocking = True)\n",
    "\n",
    "        preds = self.forward(input)\n",
    "        loss = self.loss(preds, labels)\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def val_step(self, input, labels):\n",
    "\n",
    "        input = input.to(device=device)#, non_blocking=True)\n",
    "        labels = labels.to(device=device)#, non_blocking = True)\n",
    "\n",
    "        preds = self.forward(input)\n",
    "        loss = self.loss(preds, labels)\n",
    "        accuracy = self._accuracy(preds, labels)\n",
    "\n",
    "        return {\"loss\":loss.detach(), \"accuracy\":accuracy}\n",
    "\n",
    "\n",
    "    def val_epoch_end(self, preformance_measurement_data):\n",
    "\n",
    "        accuracy = [x[\"accuracy\"].cpu().numpy() for x in preformance_measurement_data]\n",
    "        avg_accuracy = np.mean(accuracy)\n",
    "\n",
    "        loss = [x[\"loss\"].cpu().numpy() for x in preformance_measurement_data]\n",
    "        avg_loss = np.mean(loss)\n",
    "\n",
    "        return avg_loss, avg_accuracy\n",
    "\n",
    "\n",
    "    def _accuracy(self, preds, labels):\n",
    "        batch_size = len(preds)\n",
    "\n",
    "        pred_indices = torch.argmax(preds, dim=1)\n",
    "        return torch.tensor(torch.sum(pred_indices == labels).item() / batch_size)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNetBlock(nn.Module):\n",
    "    \"\"\" RestNet block with BN and full pre-activation \"\"\"\n",
    "    def __init__(self, in_channels, out_channels_conv1, out_channels_conv2, kernel_size=[3, 3], stride=[1,1], padding=[1,1]):\n",
    "        super().__init__()\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "            nn.BatchNorm2d(in_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels, out_channels_conv1, kernel_size=kernel_size[0], stride=stride[0], padding=padding[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels_conv1, out_channels_conv2, kernel_size=kernel_size[1], stride=stride[1], padding=padding[1])\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input) + input\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class ResNetBlockChangeDepth(ResNetBlock):\n",
    "    \"\"\" RestNet block with depth resize \"\"\"\n",
    "    def __init__(self, in_channels, out_channels_conv1, out_channels_conv2, res_conv_kernel_size=1, res_conv_stride=1, res_conv_padding=0, kernel_size=[3, 3], stride=[1,1], padding=[1,1]):\n",
    "\n",
    "        super().__init__(in_channels, out_channels_conv1, out_channels_conv2, kernel_size, stride, padding)\n",
    "\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels_conv2, kernel_size=res_conv_kernel_size, stride=res_conv_stride, padding=res_conv_padding)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input) + self.conv(input)\n",
    "\n",
    "\n",
    "\n",
    "class Wrapper(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.func(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(ImageClassifierNetwork):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet_block1_1 = ResNetBlock(64, 64, 64)\n",
    "        self.resnet_block1_2 = ResNetBlockChangeDepth(64, 128, 128)\n",
    "        self.resnet_block2_1 = ResNetBlock(128, 128, 128)\n",
    "        self.resnet_block2_2 = ResNetBlockChangeDepth(128, 256, 256)\n",
    "\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            # Prep 3x64x64\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 32x32x32\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2, bias=False),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 64x16x16\n",
    "\n",
    "            Wrapper(self.resnet_block1_1),\n",
    "            Wrapper(self.resnet_block1_2),\n",
    "            nn.MaxPool2d(2, 2), # 128x8x8\n",
    "\n",
    "            Wrapper(self.resnet_block2_1),\n",
    "            Wrapper(self.resnet_block2_2),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), # 256x4x4\n",
    "\n",
    "            nn.Flatten(),\n",
    "            # Fully connected layer\n",
    "            nn.Linear(4*1024, num_classes),\n",
    "            # nn.Dropout(0.5),\n",
    "            # nn.ReLU(),\n",
    "            # nn.Linear(512, num_classes)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "\n",
    "\n",
    "        # test_model\n",
    "        # self.network = nn.Sequential(\n",
    "\n",
    "        #     # Prep 3x64x64\n",
    "        #     nn.Conv2d(in_channels, 64, kernel_size=5, padding=2),\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2),  # 64x32x32\n",
    "\n",
    "        #     nn.Conv2d(64, 128, kernel_size=5, padding=2),\n",
    "        #     nn.BatchNorm2d(64),\n",
    "        #     nn.ReLU(),\n",
    "\n",
    "\n",
    "        #     Wrapper(self.resnet_block1),\n",
    "        #     nn.MaxPool2d(2, 2), # 128x8x8\n",
    "\n",
    "        #     Wrapper(self.resnet_block2),\n",
    "        #     Wrapper(self.resnet_block3),\n",
    "\n",
    "        #     nn.ReLU(),\n",
    "        #     nn.MaxPool2d(2, 2), # 256x4x4\n",
    "\n",
    "        #     nn.Flatten(),\n",
    "        #     # Fully connected layer\n",
    "        #     nn.Linear(4096, num_classes),\n",
    "        #     # nn.Dropout(0.5),\n",
    "        #     # nn.ReLU(),\n",
    "        #     # nn.Linear(2048, num_classes)\n",
    "\n",
    "        # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_2(ImageClassifierNetwork):\n",
    "\n",
    "    def __init__(self, in_channels, num_classes):\n",
    "        super().__init__()\n",
    "\n",
    "        self.resnet_block1_1 = ResNetBlock(64, 64, 64)\n",
    "        self.resnet_block1_2 = ResNetBlockChangeDepth(64, 128, 128)\n",
    "        self.resnet_block2_1 = ResNetBlock(128, 128, 128)\n",
    "        self.resnet_block2_2 = ResNetBlockChangeDepth(256, 256, 256)\n",
    "        self.resnet_block3_1 = ResNetBlock(256, 256, 256)\n",
    "        self.resnet_block3_2 = ResNetBlockChangeDepth(256, 512, 512)\n",
    "\n",
    "\n",
    "\n",
    "        self.network = nn.Sequential(\n",
    "\n",
    "            # Prep 3x64x64\n",
    "            nn.Conv2d(in_channels, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),  # 32x32x32\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            Wrapper(self.resnet_block1_1),\n",
    "            Wrapper(self.resnet_block1_2),\n",
    "            nn.MaxPool2d(2, 2),  # 128x16x16\n",
    "\n",
    "            Wrapper(self.resnet_block2_1),\n",
    "            Wrapper(self.resnet_block2_2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), # 256x8x8\n",
    "\n",
    "            Wrapper(self.resnet_block3_1),\n",
    "            Wrapper(self.resnet_block3_2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2, 2), # 512x4x4\n",
    "\n",
    "\n",
    "            nn.Flatten(),\n",
    "            # Fully connected layer\n",
    "            nn.Linear(8192, 2048),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(2048, num_classes)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.network(input)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ResNet_2' object has no attribute 'resnet_block1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mResNet_2\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# model.load_state_dict(torch.load(\"test_model.pt\"))\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mto(device)\n",
      "Cell \u001b[1;32mIn[10], line 27\u001b[0m, in \u001b[0;36mResNet_2.__init__\u001b[1;34m(self, in_channels, num_classes)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block3_1 \u001b[38;5;241m=\u001b[39m ResNetBlock(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m256\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block3_2 \u001b[38;5;241m=\u001b[39m ResNetBlockChangeDepth(\u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m512\u001b[39m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnetwork \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[0;32m     16\u001b[0m \n\u001b[0;32m     17\u001b[0m     \u001b[38;5;66;03m# Prep 3x64x64\u001b[39;00m\n\u001b[0;32m     18\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(in_channels, \u001b[38;5;241m32\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     19\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m32\u001b[39m),\n\u001b[0;32m     20\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     21\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),  \u001b[38;5;66;03m# 32x32x32\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \n\u001b[0;32m     23\u001b[0m     nn\u001b[38;5;241m.\u001b[39mConv2d(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m64\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[0;32m     24\u001b[0m     nn\u001b[38;5;241m.\u001b[39mBatchNorm2d(\u001b[38;5;241m128\u001b[39m),\n\u001b[0;32m     25\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     26\u001b[0m \n\u001b[1;32m---> 27\u001b[0m     Wrapper(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresnet_block1\u001b[49m),\n\u001b[0;32m     28\u001b[0m     Wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block2),\n\u001b[0;32m     29\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m),  \u001b[38;5;66;03m# 128x16x16\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \n\u001b[0;32m     31\u001b[0m     Wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block3),\n\u001b[0;32m     32\u001b[0m     Wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block4),\n\u001b[0;32m     33\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     34\u001b[0m     nn\u001b[38;5;241m.\u001b[39mMaxPool2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;66;03m# 256x8x8\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \n\u001b[0;32m     36\u001b[0m     Wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block3),\n\u001b[0;32m     37\u001b[0m     Wrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresnet_block4),\n\u001b[0;32m     38\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     39\u001b[0m     nn\u001b[38;5;241m.\u001b[39mAvgPool2d(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m), \u001b[38;5;66;03m# 512x4x4\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m     nn\u001b[38;5;241m.\u001b[39mFlatten(),\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Fully connected layer\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m8192\u001b[39m, \u001b[38;5;241m2048\u001b[39m),\n\u001b[0;32m     45\u001b[0m     nn\u001b[38;5;241m.\u001b[39mDropout(\u001b[38;5;241m0.5\u001b[39m),\n\u001b[0;32m     46\u001b[0m     nn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m     47\u001b[0m     nn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2048\u001b[39m, num_classes)\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m )\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1695\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1694\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1695\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ResNet_2' object has no attribute 'resnet_block1'"
     ]
    }
   ],
   "source": [
    "model = ResNet_2(3, 50)\n",
    "# model.load_state_dict(torch.load(\"test_model.pt\"))\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RestNet +- 7epoch;; RestNet_2 +- 12epoch\n",
    "epoch = 7\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "lr_scheduler = optim.lr_scheduler.OneCycleLR(optimizer, 1e-2, epochs=epoch, steps_per_epoch=int(len(train_dataset)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1776978"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_sum = 0\n",
    "for params in model.parameters():\n",
    "    params_sum+=params.view(-1).size(0)\n",
    "params_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(val_loader):\n",
    "    history_val = []\n",
    "    for input, label in val_loader:\n",
    "        history += [model.val_step(input, label)]\n",
    "\n",
    "    loss_val, acc_val = model.val_epoch_end(history_val)\n",
    "\n",
    "    return loss_val, acc_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, epoch):\n",
    "    model.train(mode=True)\n",
    "\n",
    "    #TODO Dadac agumentacjÄ™ dancyh\n",
    "\n",
    "    epoch_loss_T = []\n",
    "    batch_loss_T = []\n",
    "    epoch_loss_V = []\n",
    "    epoch_acc_V = []\n",
    "\n",
    "\n",
    "    for ep in range(epoch):\n",
    "\n",
    "        # i=1\n",
    "        for input, label in train_dataloader:\n",
    "            # print(i)\n",
    "            # i+=1\n",
    "            loss = model.train_step(input, label)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "\n",
    "            batch_loss_T += [loss.item()]\n",
    "\n",
    "        epoch_loss_T += [np.mean(batch_loss_T)]\n",
    "        batch_loss_T = []\n",
    "\n",
    "        loss_val, acc_val = eval(val_loader)\n",
    "        epoch_loss_V += [loss_val]\n",
    "        epoch_acc_V += [acc_val]\n",
    "\n",
    "        print(f'Epoch {ep}; TLoss: {epoch_loss_T[ep]}; Vloss: {loss_val}; Acc: {acc_val}')\n",
    "\n",
    "\n",
    "    model.eval()\n",
    "    return epoch_loss_T, epoch_loss_V, epoch_acc_V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0; TLoss: 2.7286988174593128; Vloss: 2.3550772666931152; Acc: 0.36447450518608093\n",
      "Epoch 1; TLoss: 2.157891220337636; Vloss: 2.2097761631011963; Acc: 0.41582202911376953\n",
      "Epoch 2; TLoss: 1.9387757222394686; Vloss: 1.975256085395813; Acc: 0.46824631094932556\n",
      "Epoch 3; TLoss: 1.6984277117896724; Vloss: 1.8465632200241089; Acc: 0.49909085035324097\n",
      "Epoch 4; TLoss: 1.5084868282885164; Vloss: 1.734597086906433; Acc: 0.5293939709663391\n",
      "Epoch 5; TLoss: 1.3252588462185215; Vloss: 1.6647933721542358; Acc: 0.5437846779823303\n",
      "Epoch 6; TLoss: 1.1549671594355557; Vloss: 1.6353799104690552; Acc: 0.561025083065033\n",
      "Epoch 7; TLoss: 0.9931440244655352; Vloss: 1.6594702005386353; Acc: 0.562301754951477\n",
      "Epoch 8; TLoss: 0.8599538948084857; Vloss: 1.697561502456665; Acc: 0.5651257038116455\n",
      "Epoch 9; TLoss: 0.7305966067958523; Vloss: 1.7883249521255493; Acc: 0.5561186075210571\n",
      "Epoch 10; TLoss: 0.5699805961670102; Vloss: 1.863176941871643; Acc: 0.5556285381317139\n",
      "Epoch 11; TLoss: 0.4158387524453369; Vloss: 1.996463656425476; Acc: 0.5555512309074402\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m loss_T, loss_V, acc_V \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[14], line 15\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(train_dataloader, epoch)\u001b[0m\n\u001b[0;32m      9\u001b[0m epoch_acc_V \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epoch):\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# i=1\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# print(i)\u001b[39;49;00m\n\u001b[0;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# i+=1\u001b[39;49;00m\n\u001b[0;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1328\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_data(data)\n\u001b[0;32m   1327\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m-> 1328\u001b[0m idx, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1329\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tasks_outstanding \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1330\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable:\n\u001b[0;32m   1331\u001b[0m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1284\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m   1283\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_thread\u001b[38;5;241m.\u001b[39mis_alive():\n\u001b[1;32m-> 1284\u001b[0m         success, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[0;32m   1286\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1132\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1119\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_get_data\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m_utils\u001b[38;5;241m.\u001b[39mMP_STATUS_CHECK_INTERVAL):\n\u001b[0;32m   1120\u001b[0m     \u001b[38;5;66;03m# Tries to fetch data from `self._data_queue` once for a given timeout.\u001b[39;00m\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;66;03m# This can also be used as inner loop of fetching without timeout, with\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1129\u001b[0m     \u001b[38;5;66;03m# Returns a 2-tuple:\u001b[39;00m\n\u001b[0;32m   1130\u001b[0m     \u001b[38;5;66;03m#   (bool: whether successfully get data, any: data if successful else None)\u001b[39;00m\n\u001b[0;32m   1131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1132\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1133\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n\u001b[0;32m   1134\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m   1135\u001b[0m         \u001b[38;5;66;03m# At timeout and error, we manually check whether any worker has\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m         \u001b[38;5;66;03m# failed. Note that this is the only mechanism for Windows to detect\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m         \u001b[38;5;66;03m# worker failures.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\queue.py:180\u001b[0m, in \u001b[0;36mQueue.get\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m remaining \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m:\n\u001b[0;32m    179\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[1;32m--> 180\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mremaining\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    181\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get()\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnot_full\u001b[38;5;241m.\u001b[39mnotify()\n",
      "File \u001b[1;32mc:\\Python311\\Lib\\threading.py:324\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    323\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m--> 324\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    326\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m waiter\u001b[38;5;241m.\u001b[39macquire(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "loss_T, loss_V, acc_V = train(train_loader, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_T' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[0;32m     13\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 15\u001b[0m plot_results(\u001b[43mloss_T\u001b[49m, loss_V, acc_V)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'loss_T' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_results(loss_T, loss_V, acc_V):\n",
    "\n",
    "    # fig = plt.figure\n",
    "    plt.plot(loss_T, label=\"Train\")\n",
    "    plt.plot(loss_V, label=\"Val\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # fig2 = plt.figure\n",
    "    plt.plot(acc_V, label=\"Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_results(loss_T, loss_V, acc_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet(3, 50)\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load(\"test_model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(val_loader):\n",
    "    history = []\n",
    "    for input, label in val_loader:\n",
    "        history += [model.val_step(input, label)]\n",
    "\n",
    "    result = model.val_epoch_end(history)\n",
    "\n",
    "    return result, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': {1.6540478}, 'accuracy': 0.6124435}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result, history = eval(val_loader)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model.state_dict(), \"10epoch_standard_model1_61acc.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNet(3, 50)\n",
    "# model.load_state_dict(torch.load(\"test_model.pt\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
